{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed20894-1f71-410f-86de-8e5b16236699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.11.0 (CPU)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9ce2b8-f1ff-4270-8d88-f9ab440f2c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: 'Documents/Data Science/DS 6050/final_project/dolphin_whale_classification/datasets # dataset root dir'\n",
      "train: '../images/train  # train images (relative to path)'\n",
      "val: '../images/val  # val images (relative to path)'\n",
      "test: ' # test images (optional)'\n",
      "nc: 1\n",
      "names:\n",
      "- fin\n"
     ]
    }
   ],
   "source": [
    "%cat datasets/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e4a400-6c52-477a-83de-4dd786b703ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually updated path, training path, validation path\n",
    "# loaded 105 images, 80/20 training/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d8021ac-1ccf-4b5c-941d-10eb36410f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jackpeele/Documents/Data Science/DS 6050/final_project/dolphin_whale_classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "496b29d6-c8ca-42e7-a031-b1b8f6f8b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('yolov5/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183d3e99-b502-41ae-a6db-a0bd92af86ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jackpeele/Documents/Data Science/DS 6050/final_project/dolphin_whale_classification/yolov5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "299ca02f-3580-4f57-a8a0-e70a6bf4019b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=dolphin_whale_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
      "fatal: cannot change to '/Users/jackpeele/Documents/Data': No such file or directory\n",
      "YOLOv5 ðŸš€ 2022-4-26 torch 1.11.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 270 layers, 7022326 parameters, 7022326 gradients, 15.8 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/Users/jackpeele/Documents/Data Science/DS 6050/final_project/d\u001b[0m\n",
      "  0%|          | 0/235 [00:00<?, ?it/s]                                         \u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):   0%|          | 1/235 [00:00<00:39,  5.91it/\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):   6%|â–‹         | 15/235 [00:00<00:03, 57.45it\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):   9%|â–‰         | 22/235 [00:00<00:03, 53.38it\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  13%|â–ˆâ–Ž        | 30/235 [00:00<00:03, 60.91it\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  16%|â–ˆâ–Œ        | 38/235 [00:00<00:03, 62.37it\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  20%|â–ˆâ–ˆ        | 47/235 [00:00<00:02, 67.93it\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  23%|â–ˆâ–ˆâ–Ž       | 55/235 [00:00<00:02, 68.45it\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  28%|â–ˆâ–ˆâ–Š       | 65/235 [00:01<00:02, 66.50it\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 77/235 [00:01<00:02, 76.39it\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 87/235 [00:01<00:01, 75.06it\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 104/235 [00:01<00:01, 84.74i\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 118/235 [00:01<00:01, 88.78i\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 127/235 [00:01<00:01, 83.15i\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 136/235 [00:01<00:01, 74.30i\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 144/235 [00:02<00:01, 74.93i\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 153/235 [00:02<00:01, 74.51i\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 162/235 [00:02<00:00, 76.04i\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 181/235 [00:02<00:00, 99.20i\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 191/235 [00:02<00:00, 94.25i\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 205/235 [00:02<00:00, 101.79\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 217/235 [00:02<00:00, 84.90i\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [00:02<00:00, 80.40i\u001b[0m\u001b[A\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/Users/jackpeele/Documents/Data Science/DS 6050/final_project/dol\u001b[0m\u001b[A\n",
      "\n",
      "  0%|          | 0/26 [00:00<?, ?it/s]                                          \u001b[A\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):   8%|â–Š         | 2/26 [00:00<00:01, 13.15it/s] \u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  19%|â–ˆâ–‰        | 5/26 [00:00<00:01, 20.29it/s] \u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 12/26 [00:00<00:00, 23.30it/s]\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/26 [00:00<00:00, 24.76it/s]\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:00<00:00, 30.17it/s]\u001b[0m\u001b[A\n",
      "Plotting labels to runs/train/exp15/labels.jpg... \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/Users/jackpeele/Documents/Data Science/DS 6050/final_project/d\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.22 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
      "Image sizes 416 train, 416 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp15\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/99        0G    0.1162   0.01937         0        25       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@WARNING: NMS time limit 0.880s exceeded\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         13      0.141      0.151     0.0273    0.00448\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/99        0G   0.09835   0.02281         0        23       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@WARNING: NMS time limit 0.880s exceeded\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         20      0.217        0.2      0.104     0.0294\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/99        0G   0.08664   0.02415         0        22       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.234      0.154     0.0725     0.0227\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/99        0G    0.0758   0.02366         0        19       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.149      0.615      0.119     0.0273\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/99        0G   0.07751     0.021         0        24       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26       0.15      0.308      0.108     0.0301\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/99        0G     0.071   0.02161         0        27       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.167      0.192      0.104      0.038\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/99        0G     0.069   0.01906         0        20       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.223      0.265      0.144     0.0535\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/99        0G     0.068   0.01981         0        29       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.412      0.538      0.426      0.142\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/99        0G   0.06586   0.01922         0        19       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.683      0.346      0.396      0.111\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/99        0G   0.06129   0.01928         0        25       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.421      0.615       0.49      0.129\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/99        0G   0.06223   0.01857         0        30       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.473      0.346      0.391      0.112\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/99        0G   0.05603   0.01622         0        27       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.597      0.577      0.525       0.16\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/99        0G   0.05428   0.01714         0        25       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.372      0.615       0.35      0.121\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/99        0G   0.05447   0.01623         0        22       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.791      0.731      0.708       0.33\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/99        0G   0.05313   0.01564         0        21       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.759      0.731      0.694      0.262\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/99        0G   0.04975   0.01618         0        24       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.762      0.615      0.566      0.223\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/99        0G   0.04921   0.01514         0        18       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.654      0.654      0.566      0.209\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/99        0G   0.05389   0.01403         0        26       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.933      0.538      0.649      0.248\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/99        0G    0.0503    0.0145         0        16       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.863      0.731      0.786      0.336\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/99        0G   0.04792   0.01406         0        21       416: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         26         26      0.904      0.731      0.821      0.388\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/99        0G   0.04724   0.01485         0        37       416:  33%|â–ˆâ–ˆâ–ˆ^C\n",
      "     20/99        0G   0.04724   0.01485         0        37       416:  33%|â–ˆâ–ˆâ–ˆ\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 668, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 563, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 349, in train\n",
      "    pred = model(imgs)  # forward\n",
      "  File \"/Users/jackpeele/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/jackpeele/Documents/Data Science/DS 6050/final_project/dolphin_whale_classification/yolov5/models/yolo.py\", line 135, in forward\n",
      "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
      "  File \"/Users/jackpeele/Documents/Data Science/DS 6050/final_project/dolphin_whale_classification/yolov5/models/yolo.py\", line 158, in _forward_once\n",
      "    x = m(x)  # run\n",
      "  File \"/Users/jackpeele/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/jackpeele/Documents/Data Science/DS 6050/final_project/dolphin_whale_classification/yolov5/models/common.py\", line 47, in forward\n",
      "    return self.act(self.bn(self.conv(x)))\n",
      "  File \"/Users/jackpeele/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/jackpeele/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return F.silu(input, inplace=self.inplace)\n",
      "  File \"/Users/jackpeele/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\", line 2031, in silu\n",
      "    return torch._C._nn.silu_(input)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 416 --batch 16 --epochs 100 --data dolphin_whale_data.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c967ef98-427d-4b4d-96e9-715731aadad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
